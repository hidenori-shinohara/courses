\documentclass[12pt, psamsfonts]{amsart}

%-------Packages---------
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{theoremref}
\usepackage{graphicx}
\usepackage[bookmarks]{hyperref}

%--------Theorem Environments--------
%theoremstyle{plain} --- default
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Id}{Id}

\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

\begin{document}

\title{Math 620 Homework Due 9/5}
\author{Hidenori Shinohara}
\maketitle

\begin{exer}
  Prove that $\delta: V \times \cdots \times V \rightarrow \mathbb{F}$ is independent of choice of basis $\{ e_i \} \subset V$ up to non-zero scalar.
\end{exer}

\begin{proof}
  Let $\{ e_i \}, \{ f_i \}$ be two bases of $V$.
  Let $v_1, \cdots, v_n \in V$ be given.
  We must show if $\delta(v_1, \cdots, v_n) = 0$ with both of the bases, or nonzero with both of the bases.
  Suppose that $\delta(v_1, \cdots, v_n) \ne 0$ with one of the bases, and it is $0$ with the other basis.
  Without loss of generality, we assume that $\{ e_i \}$ gives a nonzero value.
  Let $n \times n$ matrices $(v^i_j), (w^i_j)$ be given such that
  \begin{align*}
    \begin{bmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{bmatrix}
      &= \begin{bmatrix} v^1_1 & \cdots & v^n_1 \\ \vdots & \ddots & \vdots \\ v^n_1 & \cdots & v^n_n \end{bmatrix}
         \begin{bmatrix} e_1 \\ e_2 \\ \vdots \\ e_n \end{bmatrix} \\
      &= \begin{bmatrix} w^1_1 & \cdots & w^n_1 \\ \vdots & \ddots & \vdots \\ w^n_1 & \cdots & w^n_n \end{bmatrix}
         \begin{bmatrix} f_1 \\ f_2 \\ \vdots \\ f_n \end{bmatrix}.
  \end{align*}
  Since $\delta(v_1, \cdots, v_n) \ne 0$ with $\{ e_i \}$, $\det(v_i^j) \ne 0$.
  Therefore, the matrix $(v_i^j)$ is invertible.

  \begin{align*}
    \begin{bmatrix} e_1 \\ e_2 \\ \vdots \\ e_n \end{bmatrix}
      = \begin{bmatrix} v^1_1 & \cdots & v^n_1 \\ \vdots & \ddots & \vdots \\ v^n_1 & \cdots & v^n_n \end{bmatrix}^{-1}
         \begin{bmatrix} w^1_1 & \cdots & w^n_1 \\ \vdots & \ddots & \vdots \\ w^n_1 & \cdots & w^n_n \end{bmatrix}
         \begin{bmatrix} f_1 \\ f_2 \\ \vdots \\ f_n \end{bmatrix}.
  \end{align*}

  Let $A$ denote the product of the two matrices.
  Then $\det(A) = \det((v_i^j)^{-1}(w_i^j)) = \det(v_i^j)^{-1}\det(w_i^j) = 0$.
  This implies that the row space of $A$ has a dimension less than $n$.
  Therefore, $\{ e_1, \cdots, e_n \}$ cannot span $V$ whose dimension is $n$.

  This is a contradiction, so $\delta$ is independent of choice of basis up to nonzero scaling.
\end{proof}

\begin{exer}
  Show that $\{ e^{i_1} \otimes \cdots \otimes e^{i_k} \mid 1 \leq i_1, \cdots, i_k \leq n \}$ is a basis of $T^k(V^*)$.
  Find $\dim T^k(V^*)$.
\end{exer}

\begin{proof}
$ $
  \begin{itemize}
    \item
      Linearly independent?
      Suppose $\sum c_{i_1, \cdots, i_k} e^{i_1} \otimes \cdots \otimes e^{i_k} = 0$.
      Let $1 \leq j_1, \cdots, j_k \leq n$ be given.
      \begin{align*}
        &(\sum_{i_1, \cdots, i_k} c_{i_1, \cdots, i_k} e^{i_1} \otimes \cdots \otimes e^{i_k})(e_{j_1}, \cdots, e_{j_k}) = 0 \\
          &\implies \sum_{i_1, \cdots, i_k} c_{i_1, \cdots, i_k} (e^{i_1} \otimes \cdots \otimes e^{i_k})(e_{j_1}, \cdots, e_{j_k}) = 0 \\
          &\implies \sum_{i_1, \cdots, i_k} c_{i_1, \cdots, i_k} e^{i_1}(e_{j_1}) \cdots e^{i_k}(e_{j_k}) = 0 \\
          &\implies c_{j_1, \cdots, j_k} e^{j_1}(e_{j_1}) \cdots e^{j_k}(e_{j_k}) = 0 \\
          &\implies c_{j_1, \cdots, j_k} = 0.
      \end{align*}
      Therefore, each $c_{i_1, \cdots, i_k} = 0$.
    \item
      Span?
      Let $f \in T^k(V^*)$.
      We claim that $f = \sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})e^{i_1} \otimes \cdots \otimes e^{i_k}$.
      Let $v_1, \cdots, v_k \in V$ be given.
      Since $\{ e_1, \cdots, e_n \}$ is a basis of $V$, so each $v_i$ can be represented as $v_i = \sum_{j} c^j_ie_j$.
      \begin{align*}
        &(\sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})e^{i_1} \otimes \cdots \otimes e^{i_k})(v_1, \cdots, v_k) \\
          &= (\sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})e^{i_1} \otimes \cdots \otimes e^{i_k})(c^j_1e_j, \cdots, c^j_ke_j) \\
          &= \sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})[(e^{i_1} \otimes \cdots \otimes e^{i_k})(c^j_1e_j, \cdots, c^j_ke_j)] \\
          &= \sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})[(c^j_1e^{i_1}(e_j)) \cdots (c^j_ke^{i_k}(e_j))] \\
          &= \sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})[(c^{i_1}_1e^{i_1}(e_{i_1})) \cdots (c^{i_k}_ke^{i_k}(e_{i_k}))] \\
          &= \sum_{i_1, \cdots, i_k} f(e_{i_1}, \cdots, e_{i_k})c^{i_1} \cdots c^{i_k} \\
          &= \sum_{i_1, \cdots, i_k} f(c^{i_1}e_{i_1}, \cdots, c^{i_k}e_{i_k}) \\
          &= \sum_{i_1, \cdots, i_{k - 1}} (\sum_{i_k} f(c^{i_1}e_{i_1}, \cdots, c^{i_k}e_{i_k})) \\
          &= \sum_{i_1, \cdots, i_{k - 1}} f(c^{i_1}e_{i_1}, \cdots, c^{i_{k - 1}}e_{i_{k - 1}}, \sum_{i_k} c^{i_k}e_{i_k})) \\
          &= \sum_{i_1, \cdots, i_{k - 1}} f(c^{i_1}e_{i_1}, \cdots, c^{i_{k - 1}}e_{i_{k - 1}}, v_k) \\
          &  \vdots \\
          &= f(v_1, \cdots, v_k).
      \end{align*}
  \end{itemize}
  The dimension is $n^k$ because each $i_j$ can be any integer between $1$ and $n$.
\end{proof}

\begin{exer}
  Prove that $\{ \partial_1, \cdots, \partial_n \}$ is a basis of $T_p \mathbb{R}^n$.
\end{exer}

\begin{proof}
  TODO
\end{proof}

\begin{exer}
  Show that $\{ dx^1, \cdots, dx^n \}$ is a basis of $T_p^*\mathbb{R}^n$ that is dual to $\{ \frac{\partial}{\partial x^j} \}^n_{j = 1} \subset T_p\mathbb{R}^n$.
\end{exer}

\begin{proof}
$ $
  \begin{itemize}
    \item
      Dual?
      Let $i, j \in \{1, \cdots, n \}$.
      $dx^i(\frac{\partial}{\partial x^j}) = \frac{\partial}{\partial x^j} x^i$.
      The partial derivative of $x^i$ with respect to $x^j$ is 1 if $i = j$ and 0 otherwise.
      Thus $dx^i(\frac{\partial}{\partial x^j}) = \delta^i_j$.
    \item
      Linearly independent?
      Let $c_1, \cdots, c_n \in \mathbb{R}$ be given.
      Suppose that $c_1dx^1 + \cdots + c_ndx^n = 0$.
      For any $i \in \{ 1, \cdots, n \}$,
      \begin{align*} (c_1dx^1 + \cdots + c_ndx^n)(\partial_i) = 0
          &\implies c_1(dx^1(\partial_i)) + \cdots + c_n(dx^n(\partial_i)) = 0 \\
          &\implies c_1(\partial_i(x^1)) + \cdots + c_n(\partial_i(x^n)) = 0 \\
          &\implies c_i\partial_i(x^i) = 0 \\
          &\implies c_i = 0.
      \end{align*}
      Therefore, $c_1 = \cdots = c_n = 0$.
      Therefore, $\{ dx^1, \cdots, dx^n \}$ is indeed linearly independent.
    \item
      Span?
      Let $f \in T_p^*\mathbb{R}^n$ be given.
      We claim that $f = \sum_{i=1}^{n} f(\partial_i)dx^i$.
      Let $\sum_{i=1}^{n} c_i\partial_i \in T_p \mathbb{R}^n$ be given where $c_i$'s are in $\mathbb{R}$.
      (It makes sense to assume that every element in $T_p\mathbb{R}^n$ is in this form because we showed earlier that $\{ \partial_1, \cdots, \partial_n \}$ is a basis of $T_p \mathbb{R}^n$.)
      \begin{align*}
        (\sum_{i=1}^{n} f(\partial_i)dx^i)(\sum_{j=1}^{n} c_j\partial_j)
          &= \sum_{i=1}^{n} \big[f(\partial_i)dx^i(\sum_{j=1}^{n} c_j\partial_j)\big] \\
          &= \sum_{i=1}^{n} f(\partial_i) \big[\sum_{j=1}^{n} c_jdx^i(\partial_j)\big] \\
          &= \sum_{i=1}^{n} f(\partial_i) \big[\sum_{j=1}^{n} c_j\partial_j(x^i)\big] \\
          &= \sum_{i=1}^{n} f(\partial_i) c_i \\
          &= f(\sum_{i=1}^{n} c_i\partial_i).
      \end{align*}
  \end{itemize}
\end{proof}


\end{document}


